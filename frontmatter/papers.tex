This dissertation is based on the following publications, listed in 
chronological order:
{\raggedright
\begin{description} 
    \item[Paper \labelcref{InRu11a}] \nameref{InRu11a}
    \item[Paper \labelcref{InRu11b}] \nameref{InRu11b}
    \item[Paper \labelcref{InRu12} ] \nameref{InRu12}
    \item[Paper \labelcref{InRu14} ] \nameref{InRu14}
    \item[Paper \labelcref{InRu15a}] \nameref{InRu15a}
    \item[Paper \labelcref{InRu15b}] \nameref{InRu15b}
\end{description}}

\noindent These publications will be referenced throughout using their Roman 
numeral. 
The thesis is divided into two parts
\begin{enumerate*}[label={{}}]
    \item \emph{\nameref{Prologue}}
    \item \emph{\nameref{Papers}}
\end{enumerate*}
\nameref{Prologue} gives a coherent connection for the publications, and 
elaborates on chosen aspects. Whereas, \nameref{Papers} contains copies of the 
publications reprinted with permission from the publishers.

\clearpage
\subsection*{Mapping between \cref{Prologue} and \cref{Papers}}
The prologue will be addressing the \jsp\ scheduling problem, detailed in 
\cref{ch:scheduling} and correspond to the application in 
\cref{InRu11a,InRu12,InRu14,InRu15a,InRu15b}. The problem generators 
used are subsequently described in \cref{ch:genprobleminstances}.
From there, we try do define problem difficulty in \cref{ch:defdifficulty}, 
improving upon the ad-hoc definition from \cref{InRu12}. 
There will be two algorithms considered
\begin{enumerate*}
    \item preference learning in \cref{ch:prefmodels}, which is a tailored 
    algorithm
    \item evolutionary search in \cref{ch:esmodels}, which is a general 
    algorithm
\end{enumerate*}

The latter was implemented in \cref{InRu14}, which could be improved by 
incorporating the methodology from \cref{InRu11b}.
Preference models on  the other hand, are highly dependent on training data, 
whose collection is addressed in \cref{ch:gentrdat} using passive imitation 
learning, whereas \cref{InRu15a} included active imitation learning with 
greatly improved results. 
Moreover, the training data contains an abundance of information that can be 
used to determine aalgorithm's footprint in instance space, which was done for 
optimal solutions in \cref{InRu15b}, and in addition to that SDR based 
trajectories were inspected in \cref{ch:analysingsol} along with tying together 
the preliminary work in \cref{InRu12}. 
Finally, \cref{ch:experiments} compares to two methodologies, as the preference 
models had been significantly improved since \cref{InRu14}.
An overview of experimental settings in \cref{Papers} is given in 
\cref{papers:summary}.
    
\input{tables/papers-summary.tex}
