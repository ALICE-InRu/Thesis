This dissertation is based on the following publications, listed in 
chronological order:
{\raggedright
\begin{description} 
    \item[Paper \labelcref{InRu11a}] \nameref{InRu11a}
    \item[Paper \labelcref{InRu11b}] \nameref{InRu11b}
    \item[Paper \labelcref{InRu12} ] \nameref{InRu12}
    \item[Paper \labelcref{InRu14} ] \nameref{InRu14}
    \item[Paper \labelcref{InRu15a}] \nameref{InRu15a}
    \item[Paper \labelcref{InRu15b}] \nameref{InRu15b}
\end{description}}

\noindent These publications will be referenced throughout using their Roman 
numeral. 
The thesis is divided into two parts
\begin{enumerate*}[label={{}}]
    \item \emph{\nameref{Prologue}}
    \item \emph{\nameref{Papers}}
\end{enumerate*}
\makeatletter 
\ifthenelse{\equal{\@monograph}{true}}{
    \nameref{Prologue} gives a coherent connection for the publications, and 
    elaborates on chosen aspects.
    Whereas, \nameref{Papers} cites the publications that are referenced.    
}{
    \nameref{Prologue} gives a coherent connection for the publications, and 
    elaborates on chosen aspects, written as a monograph. 
    Whereas, \nameref{Papers} contains copies of the publications, reprinted 
    with permission from the publishers.}
\makeatother

\clearpage
\subsection*{Mapping between \cref{Prologue} and \cref{Papers}}
The prologue will be addressing the \jsp\ scheduling problem, detailed in 
\cref{ch:scheduling} and correspond to the application in 
\cref{InRu11a,InRu12,InRu14,InRu15a,InRu15b}. The problem generators 
used are subsequently described in \cref{ch:genprobleminstances}.
From there, we try do define problem difficulty in \cref{ch:defdifficulty}, 
improving upon the ad-hoc definition from \cref{InRu12}. 
There will be two algorithms considered
\begin{enumerate*}
    \item preference learning in \cref{ch:prefmodels}, which is a tailored 
    algorithm
    \item evolutionary search in \cref{ch:esmodels}, which is a general 
    algorithm
\end{enumerate*}

The latter was implemented in \cref{InRu14}, which could be improved by 
incorporating the methodology from \cref{InRu11b}.
Preference models on  the other hand, are highly dependent on training data, 
whose collection is addressed in \cref{ch:gentrdat,InRu15a} using passive 
imitation learning, whereas \cref{ch:imitation,InRu15b} included active 
imitation learning with greatly improved results. 
Moreover, the training data contains an abundance of information that can be 
used to determine algorithm's footprint in instance space, which was done for 
optimal solutions in \cref{InRu15b}, and in addition to that SDR based 
trajectories were inspected in \cref{ch:analysingsol} along with tying together 
the preliminary work in \cref{InRu12}. 
Furthermore, \cref{ch:orlibrobust} compares to two methodologies, as the 
preference models had been significantly improved since \cref{InRu14}.
An overview of experimental settings in \cref{Papers} is given in 
\cref{papers:summary}. Finally, the dissertation concludes in 
\cref{ch:conclusions} with discussion and addresses future work.
    
\input{tables/papers-summary.tex}
