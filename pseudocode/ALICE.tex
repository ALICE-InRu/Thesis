\begin{algorithm}[t]
    \caption{\fullnameAlice\ (\Alice) framework, given a 
    problem space $\mathcal{P}$, an expert policy $\pi_\star$, 
    and set of benchmark algorithms $\mathcal{A}$.} 
    \label{pseudo:alice}
    \begin{algorithmic}[1]
        \Procedure{\Alice}{$\mathcal{P},\pi_{\star},\mathcal{A}$}
        \State $Y^{\pi_\star} \gets 
        \condset{Y(\pi_{\star},\vphi(\vec{x}))}{
            \vec{x}\in\mathcal{P}}$
        \Comment{collect optimal solutions}
        \State $\Phi^{\pi_\star} \gets 
        \condset{\vphi({\pi^\star}(\vec{x}))}{
            \vec{x}\in\mathcal{P}}$
        \Comment{collect optimal meta-data}
        \ForAll{$\pi \in\mathcal{A}$} 
        \Comment{for each algorithm}
        \State $Y^{\pi} \gets 
        \condset{Y(\pi,\vphi(\vec{x}))}{
            \vec{x}\in\mathcal{P}}$
        \Comment{collect solutions}
        \State $\Phi^{\pi} \gets 
        \condset{\vphi({\pi}(\vec{x}))}{\vec{x}\in\mathcal{P}}$
        \Comment{collect meta-data}
        \State $\xi_{\pi} \gets \Exp{\given{\pi_{\star} = \pi}{\pi_{\star}}}$
        \Comment{optimality of $\pi$ (i.e. when $Y^{\pi_\star}=Y^\pi$)}
        \State $\zeta_\pi \gets$ \Call{Analyse}{$\xi_{\pi}\mapsto Y^{\pi}$}
        \Comment{relation between optimality and end-result}
        \State $\Phi^\pi \gets$ \Call{Sample}{$\Phi_\pi,\zeta_\pi$}
        \Comment{adjust set w.r.t. analysis}
        \EndFor
        \State $\Phi \gets 
        \condset{\Phi^\pi}{\pi\in\{\mathcal{A}\cup\pi_\star\}}$
        \Comment{training set}
        \State $\hat{\pi}\gets$\Call{Train}{$\Phi$} 
        \Comment{apply learning algorithm}
        \State \Return{$\hat{\pi}$} \Comment{learned policy}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}