\HeaderQuote{I don't believe there's an atom of meaning in it.}{Alice}

\chapter{Analysing Optimal Solutions}\label{ch:analysingopt} 
%\section{Probability of choosing optimal decision}\label{sec:diff:opt:rnd}
\FirstSentence{I}{n order to create successful \dr s}, a good starting point is 
to investigate the properties of optimal solutions and hopefully be able to 
learn how to mimic such `good' behaviour. 
For this, we follow an optimal solution,\footnote{Optimal solutions can be 
  obtained by using a commercial software package by \citet{gurobi}, which has 
  a free academic licence. However, GLPK by \citet{glpk} has a free licence. 
  Alas, GLPK has a lacklustre performance w.r.t. speed for for solving 
  $10\times10$ \JSP.}
and inspect the evolution of its features  (defined in \cref{tbl:features}) 
throughout the dispatching process, which is detailed in \cref{ch:gentrdat}. 
Moreover, it is noted, that there are several optimal solutions available for 
each problem instance. However, it is deemed sufficient to inspect only one 
optimal trajectory per problem instance as there are $N_{\text{train}}$ 
independent instances which gives the training data variety. 

\Cref{fig:diff:opt:unique,fig:diff:opt:rnd,fig:diff:opt:minmax} 
depict the mean over all the training data, which are quite noisy 
functions. \Cref{InRu15b} depicts the mean as is, albeit only for 
$10\times10$ problem spaces. 
Thus, for clarity purposes, they are fitted with local polynomial regression, 
making the boundary points sometimes biased. 
However, 
\cref{fig:diff:opt:SDR,fig:diff:case:OPT,fig:diff:case:SDR,fig:diff:opt:evol} 
depict the mean as is.






Firstly, we can observe that on a step-by-step basis there are several optimal 
dispatches to choose from. \Cref{fig:diff:opt:unique} depicts how the number of 
optimal dispatches evolve at each dispatch iteration. Note, that only one 
optimal trajectory is pursued (chosen at random), hence this is only a lower 
bound of uniqueness of optimal solutions.
As the number of possible dispatches decrease over time, 
\cref{fig:diff:opt:rnd} 
depicts the probability of choosing an optimal dispatch at each iteration. 

\begin{figure}
  \centering
  \subcaptionbox{$6\times5$\label{fig:diff:opt:unique:6x5}}{
    \includegraphics[width=\textwidth]{figures/{stepwise.6x5.OPT.unique}.pdf}}
  \\
  \subcaptionbox{$10\times10$\label{fig:diff:opt:unique:10x10}}{
    \includegraphics[width=\textwidth]{figures/{stepwise.10x10.OPT.unique}.pdf}}
  \caption[Number of unique optimal dispatches]{Number of unique optimal 
    dispatches (lower bound).}
  \label{fig:diff:opt:unique}
\end{figure}

\begin{figure}\centering
  \subcaptionbox{$6\times5$\label{fig:diff:opt:rnd:6x5}}{
    \includegraphics[width=\textwidth]{figures/{stepwise.6x5.OPT}.pdf}}
  \\
  \subcaptionbox{$10\times10$\label{fig:diff:opt:rnd:10x10}}{
    \includegraphics[width=\textwidth]{figures/{stepwise.10x10.OPT}.pdf}}
  \caption{Probability of choosing optimal move (at random)}
  \label{fig:diff:opt:rnd}
\end{figure}

\section{Making suboptimal decisions}\label{sec:diff:opt:sub}
Looking at \cref{fig:diff:opt:rnd}, \jrnd{10}{10} has a relatively high 
probability 
($70\%$ and above) of choosing an optimal job. However, it is imperative to 
keep making optimal decisions, because once off the optimal track the 
consequences can be dire. To demonstrate this interaction \cref{fig:diff:case} 
depicts the worst and best case scenario of \namerho, once you've fallen off 
the optimal track. Note, that this is given that you make \emph{one} wrong 
turn. Generally, there will be many mistakes made, and then the compound 
effects of making suboptimal decisions really start adding up. 
In fact, \cref{fig:diff:opt:SDR} shows the probability of optimality when 
following a fixed SDR.

It is interesting that for \JSP, that over time making suboptimal decisions 
make more of an impact on the resulting makespan. This is most likely due to 
the fact that if a suboptimal decision is made in the early stages, then there 
is space to rectify the situation with the subsequent dispatches. However, if 
done at a later point in time, little is to be done as the damage is already 
been inflicted upon the schedule. 
However, for \FSP, the case is the exact opposite. Under those circumstances 
it's imperative to make good decisions right from the get-go. This is due to 
the major structural differences between \jsp\ and \fsp, namely the latter 
having a homogeneous machine ordering, constricting the solution immensely. 
Luckily, this does have the added benefit of making \fsp\ less vulnerable for 
suboptimal decisions later in the decision process. 

\begin{figure}\centering
  \subcaptionbox{$6\times5$\label{fig:diff:case:6x5:OPT}}{
    \includegraphics[width=\textwidth]{figures/ALL/{stepwise.6x5.OPT.casescenario}.pdf}}
  \\
  \subcaptionbox{$10\times10$\label{fig:diff:case:10x10:OPT}}{
    \includegraphics[width=\textwidth]{figures/ALL/{stepwise.10x10.OPT.casescenario}.pdf}}
  \caption{Mean \namerho, for best and worst case scenario of when making
    \emph{one} sub-optimal dispatch, depicted as lower and upper bound, 
    respectively. Moreover, mean suboptimal move is given as dashed line.}
  \label{fig:diff:case:OPT}
\end{figure}
\todoFind{Remake \cref{fig:diff:case:6x5:OPT}, legend doesn't fit page!}

\section{Optimality of \sdr s}\label{sec:diff:opt:sdr}
The probability of optimality of the aforementioned SDRs from \cref{sec:SDR}, 
yet still maintaining our optimal trajectory, i.e., the probability of a job 
chosen by a SDR being able to yield an optimal makespan on a step by step 
basis, is depicted  in   \cref{fig:diff:opt:SDR}. Moreover, the dashed line 
represents the benchmark of randomly guessing the optimum (cf. 
\cref{fig:diff:opt:rnd}).

Now, let's bare in mind \namerho, of applying SDRs throughout the dispatching 
process (cf. box-plots of which in \cref{fig:SDR:boxplot}), then there is a 
some correspondence between high probability of stepwise optimality and low 
$\rho$. Alas, this isn't always the case, for \jrnd{10}{10} SPT always 
outperforms LPT w.r.t. stepwise optimality, however, this does not transcend to 
SPT having a lower $\rho$ value than LPT. Hence, it's not enough to just learn 
optimal behaviour, one needs to investigate what happens once we encounter 
suboptimal state spaces.

\section{Simple blended dispatching rule}\label{sec:diff:opt:bdr}
As stated before, the goal of this \lcnamecref{ch:problemstructure} is to 
utilise feature behaviour to motivate new, and \emph{hopefully} better, 
\dr s. 
\todoWrite{Note, MWR$\cap$SPT hardly ever coincide for easy or hard schedules 
(cf. \cref{tbl:easy:cnt:10x10,tbl:hard:cnt:10x10}, so in theory they could 
complement one another.}
A na\"ive approach would be creating a simple blended \dr\ which 
would be for instance switch between two SDRs at a predetermined time point. 
Hence, going back to \cref{fig:diff:opt:SDR} a presumably good BDR for 
\jrnd{10}{10}  would be starting with SPT and then switching over to MWR at 
around time step $k=40$, where the SDRs change places in outperforming one 
another. A box-plot for \namerho, for all $10\times10$ problem spaces is 
depicted in \cref{fig:diff:boxplot:BDR}. This little manipulation between SDRs 
does outperform SPT immensely, yet doesn't manage to gain the performance edge 
of MWR, save for \frnd{10}{10}. This gives us insight that for \jsp, the 
attribute based on MWR is quite fruitful for good dispatches, whereas the same 
cannot be said about SPT -- a more sophisticated BDR is needed to improve upon 
MWR. 

A reason for this lack of performance of our proposed BDR is perhaps that by 
starting out with SPT in the beginning, it sets up the schedules in such a way 
that it's quite greedy and only takes into consideration jobs with shortest 
immediate processing times. Now, even though it is possible to find optimal 
schedules from this scenario, as \cref{fig:diff:opt:SDR} shows, the inherent 
structure is already taking place, and might make it hard to come across 
optimal moves by simple methods. Therefore it's by no means guaranteed that by 
simply swapping over to MWR will handle the situation that applying SPT has 
already created. \Cref{fig:diff:boxplot:BDR} does however, show, that by 
applying MWR instead of SPT in the latter stages, does help the schedule to be 
more compact w.r.t. SPT. However, in the case of \jrnd{10}{10} and 
\jrndn{10}{10} the fact remains that the schedules have diverged too far from 
what MWR would have been able to achieve on its own. Preferably the blended 
dispatching rule should use  best of both worlds, and outperform all of its 
inherited DRs, otherwise it goes without saying, one would simply still use the 
original DR that achieved the best results.

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{figures/{boxplotRho.BDR.10x10}.pdf}
  \caption{Box plot for \namerho, for BDR where SPT is applied for the first 
  40\% of the dispatches, followed by MWR.}
  \label{fig:diff:boxplot:BDR}
\end{figure}

\section{Extremal feature}\label{sec:diff:opt:ext}
\todoWrite{First introduce \cref{sec:diff:opt:ext}, which is overwhelming. Then 
limit to only SDR based ones in \cref{sec:diff:opt:SDR}}
The SDRs we've inspected so-far are based on two features from 
\cref{tbl:features}, namely
\begin{enumerate*}
  \item \phiproc\ for SPT and LPT
  \item \phijobWrm\ for LWR and MWR 
\end{enumerate*}
By choosing the lowest value for the first SDR, and highest value for the 
latter SDR, i.e., the extremal values for those given features. Let's apply the 
same methodology from \cref{sec:diff:opt:sdr} to all varying features described 
in \cref{tbl:features}. 
\Cref{fig:diff:opt:minmax}
depict the probability of all extremal features being an optimal dispatch, with 
random guessing from \cref{fig:diff:opt:rnd} as a dashed line. 
\todoExtend{Discuss extremal features more?}
\todoWrite{Mention that $\rho$ for those single features is annotated on 
\cref{fig:diff:opt:minmax}} 

\begin{figure}\centering
  \subcaptionbox{\jrnd{6}{5}\label{fig:diff:extr:jrnd:6x5}}{
    \includegraphics[width=\textwidth]{figures/{j.rnd}/{stepwise.6x5.OPT.extremal}.pdf}}
  \caption{Probability of extremal feature being optimal. }
  \label{fig:diff:opt:minmax}
\end{figure}
\begin{figure}\centering
  \ContinuedFloat
  \subcaptionbox{\jrnd{10}{10}\label{fig:diff:extr:jrnd:10x10}}{
    \includegraphics[width=\textwidth]{figures/{j.rnd}/{stepwise.10x10.OPT.extremal}.pdf}}
  \caption{Continued. }
\end{figure}
\todoFind{Check if \cref{fig:diff:opt:minmax} are part of $d$ choose 1 
pref-models feature selection}
\todoExtend{Note performance edge for \phiRNDmin\ is lost from 
\cref{fig:diff:extr:jrnd:6x5} to \cref{fig:diff:extr:jrnd:10x10} as 100 random 
roll-outs are not enough for fully exploring $10\times10$ state space.}

\section{Feature evolution}\label{sec:diff:opt:evol}
In order to put the extremal features into perspective, it's worth comparing 
them with how the evolution of the features are over time, depicted in 
\cref{fig:diff:opt:evol}. 

\begin{figure}\centering
  \subcaptionbox{\jrnd{6}{5}\label{diff:evol:jrnd:6x5}}{
    \includegraphics[width=\textwidth]{figures/{j.rnd}/{stepwise.6x5.Track.evolution}.pdf}}
  \caption[Mean stepwise evolution of $\tilde{\vphi}$]{Mean stepwise evolution 
    of $\tilde{\vphi}$, which is scaled according to \cref{eq:scale}.}
  \label{fig:diff:opt:evol}
\end{figure}
\begin{figure}\centering
  %  \ContinuedFloat
  \subcaptionbox{\jrnd{10}{10}\label{diff:evol:jrnd:10x10}}{
    \includegraphics[width=\textwidth]{figures/{j.rnd}/{stepwise.10x10.Track.evolution}.pdf}}
  \caption{Continued. }
\end{figure}


\section{Emergence of problem difficulty}\label{sec:diff:stepwise}

From the experimental study it is apparent that features have different %impact 
correlation with the resulting schedule depending in what stage it is in the 
scheduling process, implying that their influence varies over the dispatching 
sequencing. Moreover, features constant throughout the scheduling process are 
not correlated with the end-result.
There are some common features for both difficulties considered which define 
\jsp\ on a whole. However, the significant features are quite different across 
the two difficulties, implying there is a clear difference in their data 
structure. The amount of significant features were considerably more for easy 
problems, indicating their key elements had been found. However, the features 
distinguishing hard problems were scarce. Most likely due to their more complex 
data structure their key features are of a more composite nature. As a result, 
new `global' features were introduced. 

It is possible for a \JSP\ schedule to have more than one sequential 
dispatching representation. It is especially w.r.t. the initial dispatches. 
Revisiting \cref{fig:example:midway}, if we were to dispatch $J_2$ 
first and then $J_4$, then that would be the same equivalent
temporal schedule if we did it the other way around. 
This is because they don't create a conflict for one another 
(as is the case for jobs $J_2$ and $J_3$). This drawback of non-uniqueness of 
sequential dispatching representation explains why there is hardly any 
significant feature for the initial steps of the scheduling process (cf. 
\cref{tbl:JSP:feat:easy} and \cref{tbl:JSP:feat:hard}). 

Since feature selection is of paramount importance in order for algorithms to 
become successful, one needs to give great thought to how features are 
selected. What kind of features yield \emph{bad} schedules? And can they be 
steered onto the path of more promising feature characteristics? This sort of 
investigation can be an indicator how to create meaningful problem generators. 
On the account that real-world problem instances are scarce, their hidden 
properties need be drawn forth in order to generate artificial problem 
instances from the same data distribution. 

The feature attributes need to be based on statistical or theoretical grounds. 
Scrutiny in understanding the nature of problem instances therefore becomes of 
paramount importance in feature engineering for learning, as it yields feedback 
into what features are important to devote more attention to, i.e., features 
that result in a failing algorithm. 
For instance, in \cref{tbl:JSP:feat:same} the slack features have the same 
distribution in the initial stages of the scheduling process. However, there is 
a clear point of divergence which needs to be investigate why the sudden 
change? \todoFind{Check best/worst case scenario}
In general, this sort of analysis can undoubtedly be used in better 
algorithm design which is more equipped to deal with varying problem instances 
and tailor to individual problem instance's needs, i.e., a footprint-oriented 
algorithm.

Although this methodology was only implemented on a set of simple 
single-priority \dr s, the methodology is easily adaptable for more 
complex algorithms, such as the learned preference models in 
\cref{sec:pref:problemstructure}. The main objective of this work is to 
illustrate the interaction of a specific algorithm on a given problem structure 
and its properties. 