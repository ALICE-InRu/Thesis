\HeaderQuote{Begin at the beginning and go on till you come to the end: then stop.}{The King}


\chapter{Introduction}\label{ch:introduction} 
%\section{Motivation and research objectives}

\FirstSentence{H}{and crafting heuristics} for NP-hard problems is a time consuming trial-and-error process, requiring inductive reasoning or problem specific insights from their human designers. Furthermore, within a problems class, such as scheduling, it is possible to construct problem instances where one heuristic would outperform another. 

Depending on the underlying data distribution of the problem instances, different heuristics perform differently. This is due to the fact that any algorithm which has superior performance in one class of problems is inevitably inferior over another class, i.e., \emph{no free lunch} theorem \citep{Wolpert97nofree}. 
%  number of “no free lunch” (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. 
The success of a heuristic is how it manages to deal with and manipulate the 
characteristics of its given problem instance. Thus, in order to understand 
more fully how a heuristic will eventually perform, one needs to look into what 
kind of problem instances are being introduced to the system. What defines a 
problem instance, e.g., what are its key features? And how can they help with 
designing better heuristics? Once the problem instances are fully understood, 
an appropriate learning algorithm can be implemented in order to create 
heuristics that are  self-adapting to its problem instances.

Given the ad-hoc nature of the heuristic design process there is clearly room 
for improvement. Recently a number of attempts have been made to automate the 
heuristic design process. 
The ultimate goal of this dissertation is to automate optimisation heuristics via ordinal regression. 
The focal point will be based on a scheduling processes named \jsp\ scheduling problem, and some of its subclass, e.g., \fsp\ scheduling problem.
There are two main viewpoints on how to approach scheduling problems, namely,	
\begin{description}
	\item[Local level] by building schedules for one problem instance at a time.
	\item[Global level] by building schedules for all problem instances at once.
\end{description}
For local level construction, a simple construction heuristic is applied, the 
schedule's features are collected at each dispatch iteration, from which a 
learning model will inspect the feature set to discriminate which operations 
are preferred to others via ordinal regression. The focus is essentially on 
creating a meaningful preference set composed of features and their ranks, as 
the learning algorithm is only run once to find suitable operators for the 
value function. 
However, for global level construction, there is no feature set collected beforehand since the learning model is optimised directly via evolutionary search. This required numerous costly value function evaluations. In fact it involves an indirect method of evaluation whether one learning model is preferable to another, w.r.t. which one yields the better expected mean. 
Evolutionary search only requires the rank of the candidates, and therefore it 
is appropriate to retain a sufficiently accurate surrogate for the value 
function during evolution in order to reduce the number of costly true value 
function evaluations. In this paradigm, ordinal regression can be used for 
surrogate assisted evolutionary optimisation, where models are ranked -- 
whereas on local level features were ranked. 

%\section{Relationship between problem structure and heuristic efficiency}
\section{Rice's framework for algorithm selection}\label{sec:rice}
The problem is to understand what underlying characteristics of the problem 
instances distinguishes \emph{good} and on the other hand \emph{bad} solutions 
when implementing a particular algorithm. \citet{SmithMilesLion5} were 
interested in discovering whether synthetic instances were in fact similar to 
real-world instances for timetabling problems. Moreover,  
\citeauthor{SmithMilesLion5} focused on how varying algorithms perform 
on different data distributions. Hence, the investigation of heuristic 
efficiency is closely intertwined to problem generation. 

In order to formulate the relationship between problem structure and heuristic efficiency one can utilise \citeauthor{Rice76}'s framework for algorithm selection problem from \citeyear{Rice76}. The framework consists of four fundamental components, namely,
\begin{description}
	\item[Problem space or instance space] $\mathcal{P}$, \hfill\\
	set of problem instances; 
	\item[Feature space] $\mathcal{F}$, \hfill\\
	measurable properties of the instances in $\mathcal{P}$;
	\item[Algorithm space] $\mathcal{A}$, \hfill\\
	set of all algorithms under inspection;
	\item[Performance space] $\mathcal{Y}$, \hfill\\
	the outcome for $\mathcal{P}$ using an algorithm from $\mathcal{A}$.
\end{description}
For a given problem instance $\vec{x}\in\mathcal{P}$ with $d$ features $\vec{\phi}(\vec{x})=\left[\phi_1(\vec{x}),...,\phi_d( \vec{x})\right]^T\in\mathcal{F}$ and using algorithm $a\in\mathcal{A}$ the performance is $y=Y(a,\vec{\phi}(\vec{x}))\in\mathcal{Y}$, where $Y:\;\mathcal{A}\times\mathcal{F} \mapsto \mathcal{Y}$ is the mapping for algorithm and feature space onto the performance space. This data collection is often referred to as meta-data. 

In the context of Rice's framework, the aforementioned approaches to scheduling problems are to maximise its expected performance: 

\begin{description}
	\item[Local level] 
	\begin{equation}
		\max_{\mathcal{F}'\subset\mathcal{F}} \mathbb{E}\left[Y\left(a,\vphi(\vec{x})\right)\right]
	\end{equation}
	The  focal point is only using  problem instances that represent the problem space, $\vec{x}\in\mathcal{P'}\subset\mathcal{P}$, in addition finding a suitable subset of the feature space, $\mathcal{F}'\subset\mathcal{F}|_{\mathcal{P}'}$. If done effectively, then the resulting learning model $a\in\mathcal{A}$ needs only be run once via ordinal regression.
	%In addition, for global level,
	\item[Global level]
	\begin{equation}
		\max_{a\in\mathcal{A}} \mathbb{E}\left[Y\left(a,\vphi(\vec{x})\right)\right]
	\end{equation}
	This is  straightforward  approach as the algorithm $a\in\mathcal{A}$ is optimised directly given the entire training data $\vec{x}\in\mathcal{P}$. Alas, this comes at a great computational cost.
\end{description}
Note, the mappings $\vphi:\mathcal{P}\mapsto\mathcal{F}$ and $Y:\mathcal{A}\mapsto\mathcal{Y}$ are the same for both paradigms.

\section{Previous work}
In order to find an optimal (or near optimal) solution for scheduling problems 
one could either use exact methods or heuristics methods. Exact methods 
guarantee an optimal solution, however, \jsp\ scheduling is strongly NP-hard 
\citep{Garey76:NPhard}. Any exact algorithm generally suffers from the curse of 
dimensionality, which impedes the application in finding the global optimum in 
a reasonable amount of time. Heuristics are generally more time efficient but 
do not necessarily attain the global optimum. Therefore, \jsp\ scheduling 
has the reputation of being notoriously difficult to solve. As a result, it's been widely studied in deterministic scheduling theory and its class of problems has been tested on a plethora of different solution methodologies from various research fields \citep{Meeran12}, all from simple and straight forward dispatching rules to highly sophisticated frameworks.

In the field of Artificial Intelligence, \cite{Meeran12} point out that despite 
their `intelligent' solutions, the effectiveness of finding the optimum has 
been rather limited. However, combined with local-search methodologies, they 
can be improved upon significantly, as \citeauthor{Meeran12} showed with the 
use of a hybrid method using Genetic Algorithms (GA) and Tabu Search (TS). 
Therefore, getting the best of both worlds, namely, the diverse global search 
obtained from GA and being complemented with the intensified local search 
capabilities of TS. 
Now, hybridisation of global and local methodologies is non-trivial. In 
general combination of the two improves performance, however, they often come 
at a great computational cost.  

Various \emph{learning} approaches have been applied to solving \jsp, such as reinforcement learning \citep{Zhang95}, evolutionary learning \citep{Tay08}, and supervised learning \citep{Siggi05,Malik08}. The approach taken in this dissertation is a supervised learning classifier using ordinal regression. 


A common way of finding a good feasible solution for \jsp\ scheduling is applying construction heuristics with some dispatching rules, e.g., choosing a task corresponding to longest or shortest operation time; most or least successors; or ranked positional weight, i.e., sum of operation times of its predecessors. Ties are broken in an arbitrary fashion or by another heuristic rule.
A summary of over $100$ classical dispatching rules for scheduling can be found in \citet{Panwalkar77}, and it is noted that these classical dispatching rules are continually used in research.  
There is no dominant rule, but the most effective have been single priority dispatching rules based on job processing attributes \citep{Haupt89}. \citet{Tay08} showed that combining dispatching rules, with the aid of genetic programming, is promising, however, there is large number of rules to choose from, thus its combinations require expert knowledge or extensive trial-and-error process. 

The current literature in scheduling focuses on different objectives, e.g., 
\citet{Chang96} minimises the due-date tightness and 
\citet{Drobouchevitch2000,Gao2007} look into solving for bottleneck machines. 
In this dissertation only minimisation of the makespan will be considered, thus 
ignoring all due-date constraints. \citet{Brandimarte1993,Xia2005,Pezzella2008} 
extend the classical \JSP\ set-up, called flexible \jsp, by allowing tasks to 
be processed by any machine from a given set, i.e., adding assignment of 
operations to the constraints.

Model assumptions can also vary, e.g., \citet{Thiagarajan05} incorporate different earliness, tardiness and holding costs. 
Moreover, it is possible to reduce \jsp\  to \fsp\ problem, since in practice most jobs in \jsp\ use the machines in the same order \citep{Guinet1998,Ho2007}.

Instead of using construction heuristics that creates \jsp\ schedules by sequentially dispatching one job at a time, one could work with complete feasible schedules and iteratively repairing them for a better result. Such was the approach by \cite{Zhang95} who studied space shuttle payload processing by using reinforcement learning, in particular, temporal difference learning. Starting with a relaxed problem, each job was scheduled as early as its temporal partial order would permit, there by initially ignoring any resource constraints on the machines, yielding the schedule's critical path. Then the schedule would be repaired so the resource constraints were satisfied in the minimum amount of iterations.
This approach of a two phased process of construction and improvement is also implemented in timetable scheduling, e.g., \citet{Asmuni09} used a fuzzy approach in considering multiple heuristic ordering in the construction process, and only allowed feasible schedules to be passed to the improvement phase. 

The alternative to hand-crafting heuristics, is to implement an automatic way of learning heuristics using a data driven approach. %Generating training data for job shop scheduling
Data can be generated using a known heuristic, such an approach is taken in \cite{Siggi05} for \jsp\, where a LPT-heuristic is applied. Afterwards, a decision tree is used to create a dispatching rule with similar logic. However, this method cannot outperform the original LPT-heuristic used to guide the search. For instruction scheduling, this drawback is confronted in \citet{Malik08,Russell09,Siggi10} by using an optimal scheduler, computed off-line. The optimal solutions are used as training data and a decision tree learning algorithm applied as before. Preferring simple to complex models, the resulting dispatching rules gave significantly better schedules than using popular heuristics in that field, and a lower worst-case factor from optimality. A similar approach is taken for timetable scheduling in \cite{Burke06}, using case based reasoning. Training data is guided by the two best heuristics for timetable scheduling. \citeauthor{Burke06} point out that in order for their framework to be successful, problem features need to be sufficiently explanatory and training data need to be selected carefully so they can suggest the appropriate solution for a specific range of new cases. Again, stressing the importance of meaningful feature selection. 

\section{Contributions}
The approach in this dissertation differs from previous studies, as it uses a simple linear combination of features found using a linear classifier based on ordinal regression.  

\todo[inline]{Discuss contributions once draft is ready...}\hfill\\\vspace{3cm}

\section{Outline}
An approach based on supervised learning on optimal schedules will be investigated and its effectiveness illustrated by improving upon well known dispatch rules for \jsp\ scheduling in \cref{ch:prefmodels}. The method of generating training data is shown to be critical for the success of the method, as shown in \cref{sec:gentrainingdata}. Moreover the choice of problem instances under consideration is worth considering, as discussed in \cref{ch:genprobleminstances}, and will be used throughout in the subsequent \lcnamecref{ch:problemstructure}s. 


The preliminary experiments done in \cref{InRu12} investigated the 
characteristics of difficult \jsp\ schedules for a single heuristic, continuing 
with that research, \cref{ch:problemstructure} compares a set of widely used 
dispatching rules on different problem spaces in the hopes of extrapolating 
where an algorithm excels in order to aid its failing aspects, which will be 
beneficial information for the creation of learning models in 
\cref{ch:prefmodels}, as they are dependant  on features based on those same 
dispatching rules under investigation.


\todo[inline]{Update outline once draft is ready...}\hfill\\\vspace{3cm}



