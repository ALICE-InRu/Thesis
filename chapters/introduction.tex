\HeaderQuote{Begin at the beginning and go on till you come to the end: then stop.}{The King}

\chapter{Introduction}\label{ch:introduction} 
%\section{Motivation and research objectives}

\FirstSentence{H}{and crafting heuristics} for NP-hard problems is a time 
consuming trial-and-error process, requiring inductive reasoning or problem 
specific insights from their human designers. Furthermore, within a problem 
class, such as scheduling, it is possible to construct problem instances where 
one heuristic would outperform another. 

Depending on the underlying data distribution of the problem, each heuristic 
performs distinctly to others. This is due to the fact that any algorithm which 
has superior performance in one class of problems is inevitably inferior over 
another class, i.e., \emph{no free lunch} theorem \citep{Wolpert97nofree}. 
%  number of “no free lunch” (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. 
The success of a heuristic is how it manages to deal with, and manipulate the 
characteristics of its given problem instance. Thus, in order to understand 
more fully how a heuristic will eventually perform, one needs to look into what 
kind of problem instances are being introduced to the system? What defines a 
problem instance, e.g., what are its key features? And how can they help with 
designing better heuristics? Once the problem instances are fully understood, 
an appropriate learning algorithm can be implemented in order to create 
heuristics that are  self-adapting to its problem instances.

Given the ad-hoc nature of the heuristic design process, there is clearly room 
for improvement. A number of attempts have been made to automate heuristic 
design, and it is the ultimate goal of this dissertation to automate 
optimisation heuristics via ordinal regression. 
The focal point will be based on a scheduling processes named \jsp\ scheduling 
problem (\JSP), and one of its subclass, the \fsp\ scheduling problem 
(\FSP).

There are two main viewpoints on how to approach scheduling problems, namely,
\begin{description}
  \item[Tailored algorithms] or constructive methods, \\
  by building schedules for one problem instance at a time.
  \item[General algorithms] or iterative methods, \\ 
  by building schedules for all problem instances at once.
\end{description}
For tailored algorithm construction
\begin{enumerate*}[label={{}}]
  \item a simple construction heuristic is applied 
  \item the schedule's features are collected at each dispatch iteration
  \item from which a learning model will inspect the feature set to 
  discriminate which operations are preferred to others via ordinal regression 
\end{enumerate*}
The focus is essentially on creating a meaningful preference set composed of 
features and their ranks, as the learning algorithm is only run \emph{once} to 
find suitable operators for the value function. 
However, for general algorithm construction, there is no feature set collected 
beforehand, since the learning model is optimised directly via evolutionary 
search. This requires numerous costly value function evaluations. 
In fact, it involves an indirect method of evaluation whether one learning 
model is preferable to another w.r.t. which one yields the better expected 
mean. 
Evolutionary search only requires the rank of the candidates, and therefore it 
is appropriate to retain a sufficiently accurate surrogate for the value 
function during evolution in order to reduce the number of costly true value 
function evaluations. 
In this paradigm, ordinal regression can be used for surrogate assisted 
evolutionary optimisation, where models are ranked -- whereas for tailored 
algorithms, features were ranked. 

%\section{Relationship between problem structure and heuristic efficiency}
\section{Rice's framework for algorithm selection}\label{sec:rice}
The aim is to understand what underlying characteristics of the problem 
instances distinguish \emph{good}, and on the other hand \emph{bad} solutions 
when implementing a particular algorithm. \citet{SmithMilesLion5} were 
interested in discovering whether synthetic instances were in fact similar to 
real-world instances for timetabling scheduling. Moreover,  
\citeauthor{SmithMilesLion5} focused on how varying algorithms perform 
on different data distributions. Hence, the investigation of heuristic 
efficiency is closely intertwined to problem generation. 
The relation between problem structure and heuristic efficiency, called 
\emph{footprints in instance space}, will be addressed in 
\cref{ch:problemstructure}.
In order to formulate the relationship for footprints, one can utilise 
\citeauthor{Rice76}'s framework for algorithm selection problem 
from \citeyear{Rice76}. The framework consists of four fundamental components:
\begin{description}
	\item[Problem space or instance space] $\mathcal{P}$, \hfill\\
	set of problem instances; 
	\item[Feature space] $\mathcal{F}$, \hfill\\
	measurable properties of the instances in $\mathcal{P}$;
	\item[Algorithm space] $\mathcal{A}$, \hfill\\
	set of all algorithms under inspection;
	\item[Performance space] $\mathcal{Y}$, \hfill\\
	the outcome for $\mathcal{P}$ using an algorithm from $\mathcal{A}$.
\end{description}
For a given problem instance $\vec{x}\in\mathcal{P}$ with $d$ features 
$\vec{\phi}(\vec{x})=\left[\phi_1(\vec{x}),...,\phi_d( 
\vec{x})\right]^T\in\mathcal{F}$ and using algorithm $a\in\mathcal{A}$ the 
performance is $y=\Upsilon(a,\vec{\phi}(\vec{x}))\in\mathcal{Y}$, where 
$\Upsilon:\;\mathcal{A}\times\mathcal{F} \mapsto \mathcal{Y}$ is the mapping 
for algorithm and feature space onto the performance space. This data 
collection is often referred to as meta-data. 

In the context of Rice's framework, the aforementioned approaches to scheduling problems are to maximise its expected performance: 

\begin{description}
  \item[Tailored algorithms] 
  \begin{equation}
    \max_{\mathcal{F}'\subset\mathcal{F}} 
    \Exp{\Upsilon\left(a,\vphi(\vec{x})\right)}
  \end{equation}
  The  focal point is only using  problem instances that represent the problem 
  space, $\vec{x}\in\mathcal{P'}\subset\mathcal{P}$, in addition finding a 
  suitable subset of the feature space, 
  $\mathcal{F}'\subset\mathcal{F}|_{\mathcal{P}'}$. If done effectively, then 
  the resulting learning model $a\in\mathcal{A}$ needs only be run once via 
  ordinal regression.
  \item[General algorithms]
  \begin{equation}
    \max_{a\in\mathcal{A}}\:\Exp{\Upsilon\left(a,\vphi(\vec{x})\right)}
  \end{equation}
  This is  straightforward  approach as the algorithm $a\in\mathcal{A}$ is 
  optimised directly given the entire instances space $\vec{x}\in\mathcal{P}$ 
  dedicated for training. Alas, this comes at a great computational cost.
\end{description}
Note, the mappings $\vphi:\mathcal{P}\mapsto\mathcal{F}$ and 
$\Upsilon:\mathcal{A}\mapsto\mathcal{Y}$ are the same for both paradigms.

A schematic flow-chart of the model selection process is illustrated in 
\cref{fig:rice}. 
Meta-data is analysed to investigate problem structure and heuristic 
effectiveness, i.e., its footprint.
Moreover, the schematic details how the preference model, which is a tailored 
algorithm, from \cref{ch:prefmodels} will come into play in the framework.

\input{figures/rice.tex}

\section{Previous work}
In order to find an optimal (or near optimal) solution for scheduling problems 
one could either use exact methods or heuristics methods. Exact methods 
guarantee an optimal solution, however, \jsp\ scheduling is strongly 
NP-hard\footnote{NP stands for Non-deterministic Polynomial-time.
    If P$\neq$NP, then NP-hard problems cannot be solved by a deterministic 
    Turing machine in polynomial time.}
\citep{Garey76:NPhard}. Any exact algorithm generally suffers from the curse of 
dimensionality, which impedes the application in finding the global optimum in 
a reasonable amount of time. Heuristics are generally more time efficient, but 
do not necessarily attain the global optimum. Therefore, \JSP\ has the 
reputation of being notoriously difficult to solve. As a result, it's 
been widely studied in deterministic scheduling theory and its class of 
problems has been tested on a plethora of different solution methodologies from 
various research fields \citep{Meeran12}, all from simple and straight forward 
\dr s to highly sophisticated frameworks.

\todoWrite{\dr s are a very useful approach to dealing with these 
    environments because they are easy to implement (by computers and shop 
    floor operators) and can cope with dynamic changes.}

\todoWrite{
    \cite{Keane15} used GP to creates features for Case Based Reasoning, which 
    were hard do understand and cumbersome in implementation due to their 
    complexity. In order to mediate the process, the \emph{Espresso Algorithm} 
    from logic circuit design was used for feature selection, 
    as `espresso' summarises the evolved features obtained by GP, yielding 
    a much simpler form that is more comprehensible for the end-user.
    The motivation for easily interpretable models, is particularly appealing, 
    even necessary in some cases. Because in some paradigms they become 
    essential for getting them sanctioned, e.g., due to legislation for 
    implementation of uninhabited aerial vehicles (i.e. drones).
}

In the field of Artificial Intelligence, \cite{Meeran12} point out that despite 
their `intelligent' solutions, the effectiveness of finding the optimum has 
been rather limited. However, combined with local-search methodologies, they 
can be improved upon significantly, as \citeauthor{Meeran12} showed with the 
use of a hybrid method involving Genetic Algorithms (GA) and Tabu Search (TS). 
Therefore, getting the best of both worlds, namely
\begin{enumerate*}[label={{}}]
  \item the diverse global search obtained from GA 
  \item being complemented with the intensified local search capabilities of TS
\end{enumerate*}
Unfortunately, hybridisation of global and local methodologies is non-trivial. 
In general, combination of the two improves performance, however, they often 
come at a great computational cost.  

Various \emph{learning} approaches have been applied to solving \jsp\ 
scheduling, such as\todoExtend{More learning methods for \JSP}
\begin{enumerate*}
  \item reinforcement learning \citep{Zhang95}
  \item evolutionary learning \citep{Tay08}
  \item supervised learning \citep{Siggi05,Malik08}
\end{enumerate*}
The approach taken in this 
dissertation is a supervised learning classifier using ordinal regression. 


A common way of finding a good feasible solution for \JSP\ is 
applying construction heuristics with some \dr s, e.g., choosing a task 
corresponding to
\begin{enumerate*}[itemjoin*={{, or }}]
  \item longest or shortest processing time
  \item most or least successors (i.e. operation number)
  \item ranked positional weight, i.e., sum of processing times of its 
  predecessors or successors
\end{enumerate*} 
Ties are broken in an arbitrary fashion or by another heuristic rule.
A summary of over $100$ classical \dr s for scheduling can be found in 
\citet{Panwalkar77}, and it is noted that these classical \dr s are continually 
used in research.  
There is no dominant rule, but the most effective have been \sdr s based on job 
processing attributes \citep{Haupt89}. \citet{Tay08} showed that combining \dr 
s, with the aid of genetic programming, is promising. However, there is large 
number of rules to choose from, thus their combinations require expert 
knowledge or extensive trial-and-error process.

The literature in scheduling mainly focuses on different objectives, 
\todoWrite{Relocate somewhere else}
\todoFind{Add multiobjective \jsp\ citations}
e.g., \citet{Chang96} minimised the due-date tightness and 
\citet{Drobouchevitch2000,Gao2007} looked into solving for bottleneck machines. 
In this dissertation only minimisation of the makespan will be considered, thus 
ignoring all due-date constraints. 
Model assumptions (i.e. shop floor constraints) can also vary, e.g., 
\citet{Thiagarajan05} incorporate different earliness, tardiness and holding 
costs. 
\citet{Brandimarte1993,Xia2005,Pezzella2008} extend the classical \JSP\ set-up, 
called \emph{flexible} \jsp, by allowing tasks to be processed by any machine 
from a given set, i.e., adding assignment of operations to the constraints.
Moreover, it is possible to reduce \JSP\ to a \FSP, since in practice, 
most jobs in the \jsp\ use the machines in the same order 
\citep{Guinet1998,Ho2007}.

Instead of using construction heuristics that creates \jsp\ schedules by sequentially dispatching one job at a time, one could work with complete feasible schedules and iteratively repairing them for a better result. Such was the approach by \cite{Zhang95} who studied space shuttle payload processing by using reinforcement learning, in particular, temporal difference learning. Starting with a relaxed problem, each job was scheduled as early as its temporal partial order would permit, there by initially ignoring any resource constraints on the machines, yielding the schedule's critical path. Then the schedule would be repaired so the resource constraints were satisfied in the minimum amount of iterations.
This approach of a two phased process of construction and improvement is also implemented in timetable scheduling, e.g., \citet{Asmuni09} used a fuzzy approach in considering multiple heuristic ordering in the construction process, and only allowed feasible schedules to be passed to the improvement phase. 

The alternative to hand-crafting heuristics, is to implement an automatic way of learning heuristics using a data driven approach. %Generating training data for job shop scheduling
Data can be generated using a known heuristic, such an approach is taken in 
\cite{Siggi05} for \jsp\, where a LPT-heuristic is applied. Afterwards, a 
decision tree is used to create a \dr\ with similar logic. However, this method 
cannot outperform the original LPT-heuristic used to guide the search. For 
instruction scheduling, this drawback is confronted in 
\citet{Malik08,Russell09,Siggi10}, by using an optimal scheduler, computed 
off-line. The optimal solutions are used as training data and a decision tree 
learning algorithm is applied as before. Preferring simple to complex models, 
the resulting \dr s gave significantly better schedules than using popular 
heuristics in that field, and a lower worst-case factor from optimality. A 
similar approach is taken for timetable scheduling in \cite{Burke06}, using 
case based reasoning, where training data is guided by the two best heuristics 
in the field. 
\citeauthor{Burke06} point out that in order for their framework to be 
successful, problem features need to be sufficiently explanatory and training 
data needs to be selected carefully so they can suggest the appropriate 
solution for a specific range of new cases. 
Again, stressing the importance of meaningful feature selection. 

\section{Supplementary material}
The Prologue will mostly focus on traditional \jsp\ problem instances. 
However, in \cref{ch:genprobleminstances} there is a greater variety of problem 
spaces introduced, and when seen fit some of them will be investigated as well 
in the subsequent \lcnamecref{ch:problemstructure}s. 
Since most experiments have been run on all problem spaces, they can be 
inspected in the supplementary \href{http://tgax89.rhi.hi.is:3838/alice}{Shiny 
application written in R}. 
In addition, all source code and data is freely distributed from:
\begin{quote}
    \url{https://github.com/ALICE-InRu/}
\end{quote}
under the permissive creative commons share-alike 
licence.\footnote{Attribution-ShareAlike 4.0 International 
(\href{http://creativecommons.org/licenses/by-sa/4.0/}{CC BY-SA 4.0})}

\section{Contributions}

The initial goal of the Ph.D. project was to use sophisticated algorithms for 
preference learning on hard problems, in particular \jsp\ scheduling, and find 
ways to mediate the computational effort that they require.
After painstaking parameter tuning, and managing to find complex models 
with high training accuracy. Alas, severely overfitted to the training 
instances -- a simple linear model would suffice with similar performance, and 
for much less overhead! Also, linear models come with the added benefit of easy 
interpretability. 

Unfortunately, there is not much said about algorithms that fail 
\citep{SmithMiles2015}, as the focus tend to be on claiming superiority in 
performance to some previous approach.
So to quote a pioneer in scheduling, 
\begin{quote}
    ``The only real mistake is the one from which we learn nothing'' \\
    \raggedleft Henry Ford
\end{quote}
In order to make the best of a bad situation, this derailment\footnote{
    This explains why \cref{InRu11b} is completely different from the other 
    publications.} 
designed the course of the body of work presented in this dissertation. 
Namely, by dwelling on optimal solutions and try to understand 
their fundamental building blocks, and applying what you learn on \emph{simple} 
models, before investing valuable time and resources in implementing the 
current state-of-the-art algorithms. 
The research questions that are put forth are
\begin{enumerate*}[itemjoin={{? }}, itemjoin*={{? And ultimately, }},
    after={{?}}]
    \item how are optimal solutions \emph{supposed} to behave -- what are the 
    key indicators
    \item Where and when should there be emphasis on learning
    \item what states of our problem are worth investigating further to achieve 
    the desired result
\end{enumerate*}

Hopefully, this preparatory work helps recognising any limitations, and will 
lead to better algorithm design, or at least improved understanding of 
\emph{why} the models are performing in the way that they do.
It's the believe of the author, that the methodology of going about this, which 
is roughly described in \cref{pseudo:alice}, can be applied to any kind of 
optimisation problem. As such, then it's suitable to name the framework:
\emph{\fullnameAlice}, or \Alice\footnote{
    The hopefully catchy and very deliberate ``backronym,'' pays homage to 
    the wonderful literary character, Alice in Wonderland--a personal 
    favourite of the author.} 
for short. 
For demonstration purposes, this dissertation will solely be 
focusing on applying \Alice\ to \dr s for \jsp\ scheduling.

\input{pseudocode/ALICE}


\todoWrite{$\xi_\pi$ can be interpreted as training accuracy.\\
    Post-processing: apply analysis on $\hat{\pi}$ (learned policy), i.e., 
    $\xi_{\hat{\pi}}$ and $\zeta_{\hat{\pi}}$.}


\section{Outline}\todoWrite{Update outline once draft is ready...}
An approach based on supervised learning, mostly on optimal schedules will be 
investigated and its effectiveness illustrated by improving upon well known 
dispatch rules for \jsp\ scheduling in \cref{ch:prefmodels}. The method of 
generating training data is shown to be critical for the success of the method, 
as shown in \cref{sec:gentrainingdata}. Moreover the choice of problem 
instances under consideration is worth considering, as discussed in 
\cref{ch:genprobleminstances}, and will be used throughout in the subsequent 
\lcnamecref{ch:problemstructure}s. 

The preliminary experiments done in \cref{InRu12} investigated the 
characteristics of difficult \jsp\ schedules for a single heuristic, continuing 
with that research, \cref{ch:problemstructure} compares a set of widely used 
\dr s on different problem spaces in the hopes of extrapolating 
where an algorithm excels in order to aid its failing aspects, which will be 
beneficial information for the creation of learning models in 
\cref{ch:prefmodels}, as they are dependant  on features based on those same 
\dr s under investigation.

Due to scarcity of real-world data, we let random problem generators 
suffice, that are described in \cref{ch:gentrdat}. Moreover, the traditional 
OR-Library benchmark instances are similarly created, although for a greater 
variety of problem sizes. 
\citet{SmithMiles2015} warn that general practice in the OR-community is 
over-tuning of algorithms to a relatively small set of aging\footnote{
    The OR-Library problem instances are mostly from the 1980s and 
    1990s, or earlier (cf. \cref{tbl:data:orlib}).}
instances. 
Obviously, the choice of data set has a direct influence of the proposed 
algorithm. As they are developed with them specifically in mind. 
This is why robustness towards different problem spaces, than initially trained 
on, is of so much value, as it indicates how applicable our model is for 
real-world deployment 

\todoWrite{our ability to learn about the strengths and weaknesses of 
algorithms from empirical evidence}

\clearpage

\noindent \textbf{Chapter to Paper relation}
\begin{enumerate}
  \item \cref{ch:scheduling} --
  \cref{InRu11a,InRu12,InRu14,InRu15a,InRu15b,InRu15c}
  \item \cref{ch:genprobleminstances} --
  \cref{InRu11a,InRu12,InRu14,InRu15a,InRu15b,InRu15c}
  \item \cref{ch:problemstructure} -- \cref{InRu12}
  \item \cref{ch:analysingopt} -- \cref{InRu15b}
  \item \cref{ch:prefmodels} -- \cref{InRu11a,InRu15a,InRu15b,InRu15c}
  \item \cref{ch:esmodels} -- \cref{InRu14}, which could be improved by 
  incorporating the methodology from \cref{InRu11b}
  \item \cref{ch:experiments} -- \cref{ch:prefmodels} vs. \cref{ch:esmodels}
\end{enumerate}

\Cref{jsp:methods} summarise the main techniques applied to solve \JSP. The 
figure is based on Fig. 1 from \citet{Jain99}, however, updated to reflect the 
previous work relevant to this dissertation.

Some notes
\begin{description}
  \item[Local Search] \cite{LocalSearch} divide approximations methods to 
  \begin{enumerate}
    \item iterative methods, which starts with some initial feasible 
    solution, and its neighbourhood is searched for one with lower cost. If 
    such a solution is found, the algorithm is
    continued from there; otherwise, a local minimum has been found
    \item constructive methods, construct a complete schedule and apply 
    local search to partial schedules on the way
  \end{enumerate}
  \item[Greedy randomized adaptive search procedure] (GRASP) for \JSP\ by 
  \cite{GRASP}
  \item[Beam search] by \cite{BeamSearch} is an adaptation of the branch and 
  bound method in which only some nodes are evaluated in the search tree. At 
  any level, only the promising nodes are kept for further branching and 
  remaining nodes are pruned off permanently.
  \item[Insertion Algorithm] \cite{InsertionAlg} 
\end{description}

\input{figures/methods-flowchart.tex}
\input{tables/papers-summary.tex}
