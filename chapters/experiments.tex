\HeaderQuote{The adventures first... explanations take such a dreadful 
time.}{The Gryphon} 


\chapter{OR-Library Comparison}\label{ch:experiments} 

\FirstSentence{U}{ntil only evolutionary search models} from \cref{ch:esmodels} have been checked for robustness. This was done to show the impact of choice of objective function \cref{eq:cma:objfun}. 
However, there was no reference made to other models, except for demonstrating how far off the result was from the best known solutions (BKS).
Now we will also consider the best configurations for preference models in \cref{ch:prefmodels,ch:featselect,ch:imitation,ch:rollout}.
Although, all models will be using the same training data \jrnd{10}{10}.

From \cref{ch:rollout} only preference models using \phiSDRRelated\ will be 
considered, and only one configuration for \phiRNDRelated\ as it is quite 
computationally expensive for OR-Library 
as some of the problem dimensions, $K$, is too great for 100 random roll-outs 
for each possible encountered operation. However, using only four fixed 
roll-outs is reasonable.
Moreover, applying $(K-k)$-step lookahead, then it is sensible to keep track of 
the best solution found (even though they had not been specifically followed 
further). This was referred to as its \emph{fortified} solution, where 
$\rho_{\text{fort.}}\leq\rho$. To keep notation short, only 
$\rho_{\text{fort.}}$ is reported for models that incorporate any 
\phiGlobalRelated\ features. 

\begin{figure}[t]
\includegraphics[width=\textwidth]{{boxplot.ORLIB}.pdf}
\caption{Box-plot for deviation from best known solution, $\rho$, trained on
\jrnd{10}{10}}\label{fig:comp:orlib}
\end{figure}
\input{tables/stats.orlib}
\pagebreak

\input{tables/summary.orlib}


\todoWrite{Summarise results}
