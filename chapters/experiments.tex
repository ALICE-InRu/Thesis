\HeaderQuote{The adventures first... explanations take such a dreadful 
time.}{The Gryphon} 


\chapter{OR-Library Comparison}\label{ch:experiments} 
\todoWrite{Compare CMA-ES to PREF models}

\FirstSentence{T}{here's something to be said} for having a good opening line. 

\todoWrite{When applying global (or roll-out) features from \cref{tbl:features} 
as was done in \cref{ch:rollout}, then is sensible to keep track of the best 
solution found (even though they hadn't been followed), this was referred to as 
its \emph{fortified} solution.}

From \cref{ch:rollout} only preference models using \phiSDRRelated\ will be 
considered, as \phiRNDRelated\ are too computational expensive for OR-Library 
as some of the problem dimensions, $K$, is too great for 100 random roll-outs 
for each possible encountered operation. However, using only four fixed 
roll-outs is reasonable.

\begin{figure}[t]
\includegraphics[width=\textwidth]{{boxplot.ORLIB}.pdf}
\caption{Box-plot for deviation from best known solution, $\rho$, trained on
\jrnd{10}{10}}\label{fig:comp:orlib}
\end{figure}
\input{tables/stats.orlib}
\pagebreak

\begin{table}
  \noindent
  \begin{minipage}{\textwidth}
  \caption[Frequency of finding best makespan]{Frequency a model configuration 
  found the best\footnote{Only for \texttt{la12} the best value is BKS.} 
  makespan}
  \centering
  \begin{tabular}{lclr}
    \toprule
    Model & CDR & Configuration & $\%$ \\ 
    \midrule
    CMA-ES & 16.1 & $\minCmax$ & 15.05 \\ 
    CMA-ES & 16.1 & $\minRho$ & 15.96 \\ 
    \midrule
    PREF & 3.524 & OPT.equal & 6.19 \\ 
    PREF & 16.1 & ES.Cmax.adjdbl2nd & 10.42 \\ 
    PREF & 16.1 & DA2UNSUP.adjdbl2nd & 7.29 \\ 
    PREF & 16.1 & OPT.equal & 0.00 \\ 
    PREF & 16.1 & OPT$\epsilon$.equal & 0.99 \\ 
    PREF & 16.1 & ES.Cmax.equal & 4.04 \\ 
    \midrule
    PREF & 20.1 & OPT.adjdbl2nd & 16.30 \\ 
    PREF & 20.1 & ES.Cmax.adjdbl2nd & 57.45 \\ 
    \bottomrule
  \end{tabular}
  \end{minipage}
\end{table}

The weights for \cref{eq:CDR:feat} in \cref{InRu11a} were found using 
supervised learning, where the training data was created from optimal solutions 
of randomly generated problem instances. As an alternative, this study showed  
that minimising the mean makespan directly using a brute force search via 
CMA-ES actually results in a better CDRs. The nature of CMA-ES is to explore 
suboptimal routes until it converges to an optimal one. Implying that the 
previous approach of only looking into one optimal route may not produce a 
sufficiently rich training set. That is, \PhiSet{\pi} should incorporate a 
more complete knowledge on \emph{all} possible preferences, i.e., make also the 
distinction between suboptimal and sub-suboptimal features, etc.  This would 
require a Pareto ranking of preferences which can be used to make the 
distinction to which feature sets are equivalent, better or worse -- and to 
what degree, i.e., by giving a weight to the preference. This would result in a 
very large training set, which of course could be re-sampled in order to make 
it computationally feasible to learn.
